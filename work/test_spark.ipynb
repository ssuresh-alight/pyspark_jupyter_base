{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85fc1993-04bf-48da-b6f4-b57a31e3be7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T22:09:31.036188Z",
     "start_time": "2025-02-18T22:09:30.166646Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "from pyspark.sql import SparkSession, Row, functions as F\n",
    "from time import perf_counter\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# type hint thingies\n",
    "from typing import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3a1ac26-92ed-457b-aec6-de2e7748f9de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T22:09:36.009720Z",
     "start_time": "2025-02-18T22:09:31.050614Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spark session & context\n",
    "\n",
    "# create it in local mode\n",
    "spark = SparkSession.builder.master(\"local\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecae6682-1234-42ec-bbf6-05015ff221b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T22:09:37.809709Z",
     "start_time": "2025-02-18T22:09:36.368297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: 20100\n",
      "Took 0.1385273230043822ms\n"
     ]
    }
   ],
   "source": [
    "# Sum of the first 100 whole numbers\n",
    "rdd = sc.parallelize(range(200 + 1))\n",
    "\n",
    "start = perf_counter()\n",
    "print(\"Sum:\", rdd.sum())\n",
    "print(f\"Took {perf_counter()-start}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4aaef821-1d35-4e80-8376-4c3756f113c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T22:09:38.525503Z",
     "start_time": "2025-02-18T22:09:37.839714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates dataframe. No explicit schema specified - will sample row to get schema instead\n",
    "# Alternatively can pass in `schema` param\n",
    "# Dataframe can be created from pandas DF as well\n",
    "df = spark.createDataFrame([\n",
    "    Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),\n",
    "    Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),\n",
    "    Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))\n",
    "])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a444f13d-3022-4ec1-9c24-91c4a834cb46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T22:09:38.715192Z",
     "start_time": "2025-02-18T22:09:38.558553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandaas dataframe is created col by col\n",
    "pandas_df = pd.DataFrame({\n",
    "    'a': [1, 2, 3],\n",
    "    'b': [2., 3., 4.],\n",
    "    'c': ['string1', 'string2', 'string3'],\n",
    "    'd': [date(2000, 1, 1), date(2000, 2, 1), date(2000, 3, 1)],\n",
    "    'e': [datetime(2000, 1, 1, 12, 0), datetime(2000, 1, 2, 12, 0), datetime(2000, 1, 3, 12, 0)]\n",
    "})\n",
    "df = spark.createDataFrame(pandas_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "568d8ab9-a5f2-41cf-8fc1-81f58d9205b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T22:09:40.811340Z",
     "start_time": "2025-02-18T22:09:38.747532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
      "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n",
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- c: string (nullable = true)\n",
      " |-- d: date (nullable = true)\n",
      " |-- e: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a2cf40c-69be-4ebb-b7f9-0001d276b78e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T22:09:41.144625Z",
     "start_time": "2025-02-18T22:09:40.856960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>a</th><th>b</th><th>c</th><th>d</th><th>e</th></tr>\n",
       "<tr><td>1</td><td>2.0</td><td>string1</td><td>2000-01-01</td><td>2000-01-01 12:00:00</td></tr>\n",
       "<tr><td>2</td><td>3.0</td><td>string2</td><td>2000-02-01</td><td>2000-01-02 12:00:00</td></tr>\n",
       "<tr><td>3</td><td>4.0</td><td>string3</td><td>2000-03-01</td><td>2000-01-03 12:00:00</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eager evaluation - displays like this in jupyter\n",
    "# spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4de36d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configure logging - find non-worker logs in docker container\n",
    "# logging.basicConfig(level=logging.INFO, filename=\"log.txt\")\n",
    "# logger = logging.getLogger(__name__)\n",
    "# logger.info(\"test from outside\")\n",
    "\n",
    "def pandas_filter_func(iterator: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "    # logger.info(\"test from func\") # not sure how to see these\n",
    "    for pandas_df in iterator:\n",
    "        yield pandas_df[pandas_df.a == 1]\n",
    "\n",
    "df.mapInPandas(pandas_filter_func, schema=df.schema).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "188667d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://8fd66782d827:4040'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.uiWebUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b42d4bac-01a7-4d6a-8de6-38b2235c3038",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T22:09:42.149111Z",
     "start_time": "2025-02-18T22:09:41.184074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, city: string, id: bigint]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = spark.createDataFrame([\n",
    "    Row('don','baltimore',12),\n",
    "    Row('jerry','boston',19),\n",
    "    Row('bob','baltimore',99),\n",
    "    Row('cameron','baltimore',13),\n",
    "    Row('james','seattle',1),\n",
    "    Row('peter','seattle',2),\n",
    "], schema = 'name: string, city: string, id: long')\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6aafd6d6-6264-4a0d-bf93-9e1d4e47db13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T22:09:42.227426Z",
     "start_time": "2025-02-18T22:09:42.223249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|     city|count|\n",
      "+---------+-----+\n",
      "|   boston|    1|\n",
      "|  seattle|    2|\n",
      "|baltimore|    3|\n",
      "+---------+-----+\n",
      "\n",
      "+---------+-------------------+\n",
      "|     city|  collect_set(name)|\n",
      "+---------+-------------------+\n",
      "|   boston|            [jerry]|\n",
      "|  seattle|     [peter, james]|\n",
      "|baltimore|[bob, cameron, don]|\n",
      "+---------+-------------------+\n",
      "\n",
      "+---------+-------------------+\n",
      "|     city|  collect_set(name)|\n",
      "+---------+-------------------+\n",
      "|   boston|            [jerry]|\n",
      "|  seattle|     [peter, james]|\n",
      "|baltimore|[bob, cameron, don]|\n",
      "+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy('city').count().show()\n",
    "\n",
    "df2.groupby(\"city\").agg({'name': 'collect_set'}).show()\n",
    "\n",
    "df2.groupby(\"city\").agg(F.collect_set('name')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b223c8aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T22:09:42.284073Z",
     "start_time": "2025-02-18T22:09:42.280158Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c7e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
